{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quora-insincere-questions-classification']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import plotly.offline as py\n",
    "from plotly.offline import init_notebook_mode,iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix,f1_score,roc_curve,make_scorer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "import scikitplot as skplt\n",
    "import seaborn as sns\n",
    "import time\n",
    "print(os.listdir(\"../input\"))\n",
    "stopwords=set(stopwords.words('english'))\n",
    "stemmer=SnowballStemmer('english')\n",
    "seed=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding,SpatialDropout1D,Dropout,CuDNNLSTM,Bidirectional\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import Callback,EarlyStopping,ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('../input/quora-insincere-questions-classification/train.csv')\n",
    "test=pd.read_csv('../input/quora-insincere-questions-classification/test.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target1=data[data['target']==1]\n",
    "#target0=data[data['target']==0]\n",
    "#sampled_size=target1.shape[0]\n",
    "#sampled_target0=target0.sample(sampled_size,random_state=seed)\n",
    "#new_data=pd.concat([target1,sampled_target0],axis=0)\n",
    "#Shuffling the data\n",
    "#new_data=new_data.sample(frac=1,random_state=seed).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data=data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre-processing for deeplearning, Removing only the punctuations. Stop words might be helpful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_for_nn(text):\n",
    "    tokenized_word=word_tokenize(text)\n",
    "    filtered_words=[word.lower() for word in tokenized_word if word not in string.punctuation]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['question_text']=new_data['question_text'].apply(lambda x: filter_for_nn(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=new_data.question_text\n",
    "Y=new_data.target\n",
    "\n",
    "train_X,val_X,train_y,val_y=train_test_split(X,Y,test_size=0.01,random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting text to sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "token=Tokenizer()\n",
    "token.fit_on_texts(train_X.values)\n",
    "train_seq=token.texts_to_sequences(train_X.values)\n",
    "val_seq=token.texts_to_sequences(val_X.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=100\n",
    "train_pad=pad_sequences(train_seq,maxlen=maxlen)\n",
    "val_pad=pad_sequences(val_seq,maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1293060,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=to_categorical(train_y.values)\n",
    "val_y=to_categorical(val_y.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary=token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1293060, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting our own Embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 300)          60564600  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 100, 300)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200)               321600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               102912    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 60,990,138\n",
      "Trainable params: 60,990,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_len=300\n",
    "model=Sequential()\n",
    "model.add(Embedding(len(vocabulary)+1,embedding_len,input_length=maxlen))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(Bidirectional(CuDNNLSTM(100)))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.5,seed=seed))\n",
    "#model.add(Dense(512,activation='relu'))\n",
    "#model.add(Dropout(0.5,seed=seed))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "est=EarlyStopping(monitor='val_loss',patience=10,restore_best_weights=True)\n",
    "rlr=ReduceLROnPlateau(monitor='val_loss',patience=10,min_lr=0.0001,factor=0.1)\n",
    "call_back=[est,rlr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1293060 samples, validate on 13062 samples\n",
      "Epoch 1/2\n",
      "1293060/1293060 [==============================] - 168s 130us/step - loss: 0.1185 - val_loss: 0.1052\n",
      "Epoch 2/2\n",
      "1293060/1293060 [==============================] - 158s 123us/step - loss: 0.0970 - val_loss: 0.1047\n"
     ]
    }
   ],
   "source": [
    "result1=model.fit(train_pad,train_y,epochs=2,batch_size=512,validation_data=[val_pad,val_y],callbacks=call_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for Validation data without pre-trained embeddings: 0.6124469589816125\n",
      "F1 score for Train data without pre-trained embeddings: 0.7150980119560684\n"
     ]
    }
   ],
   "source": [
    "pred1_proba=model.predict(val_pad)\n",
    "pred1=np.argmax(pred1_proba,axis=1)\n",
    "score1=f1_score(np.argmax(val_y,axis=1),pred1)\n",
    "print(\"F1 score for Validation data without pre-trained embeddings:\",score1)\n",
    "\n",
    "train_pred1_proba=model.predict(train_pad)\n",
    "train_pred1=np.argmax(train_pred1_proba,axis=1)\n",
    "train_score1=f1_score(np.argmax(train_y,axis=1),train_pred1)\n",
    "print(\"F1 score for Train data without pre-trained embeddings:\",train_score1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Simple Bidirectional LSTM with own embeddings with only 5 epochs has worked better than XGBClassifier! But this model used significantly more data than XGBClassifier. But we can see that this model is overfitting. You can train it for around 100 epochs. We have set patience=10 in callbacks and so they are definitely not effective in 5 epochs. During 100 epochs, they will help in not overfitting. You can reduce the learning rate of Adam optimizer to reduce overfitting aswell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking Embeddings from GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Embedding_file='../input/quora-insincere-questions-classification/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "def get_coefs(word,*arr):return word,np.asarray(arr,dtype='float32')\n",
    "embeddings_index=dict(get_coefs(*o.split(\" \")) for o in open(Embedding_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3249: FutureWarning:\n",
      "\n",
      "arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_stack=np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std=embedding_stack.mean(),embedding_stack.std()\n",
    "embedding_matrix=np.random.normal(emb_mean,emb_std,(len(vocabulary)+1,embedding_stack.shape[1]))\n",
    "for word,i in vocabulary.items():\n",
    "    embedding_vector=embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i]=embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=Sequential()\n",
    "model2.add(Embedding(embedding_matrix.shape[0],embedding_matrix.shape[1],weights=[embedding_matrix],input_length=maxlen))\n",
    "model2.add(SpatialDropout1D(0.3))\n",
    "model2.add(Bidirectional(CuDNNLSTM(100)))\n",
    "model2.add(Dense(512,activation='relu'))\n",
    "model2.add(Dropout(0.5,seed=seed))\n",
    "#model2.add(Dense(512,activation='relu'))\n",
    "#model2.add(Dropout(0.8,seed=seed))\n",
    "model2.add(Dense(2,activation='softmax'))\n",
    "model2.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1293060 samples, validate on 13062 samples\n",
      "Epoch 1/2\n",
      "1293060/1293060 [==============================] - 682s 528us/step - loss: 0.1106 - val_loss: 0.0992\n",
      "Epoch 2/2\n",
      " 186560/1293060 [===>..........................] - ETA: 9:40 - loss: 0.0931"
     ]
    }
   ],
   "source": [
    "result2=model2.fit(train_pad,train_y,epochs=2,batch_size=64,validation_data=[val_pad,val_y],callbacks=call_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for Validation data using GloVe Embeddings: 0.6657700067249496\n",
      "F1 Score for Train data using GloVe Embeddings: 0.7331004401286835\n"
     ]
    }
   ],
   "source": [
    "pred2_proba=model2.predict(val_pad)\n",
    "pred2=np.argmax(pred2_proba,axis=1)\n",
    "score2=f1_score(np.argmax(val_y,axis=1),pred2)\n",
    "print(\"F1 score for Validation data using GloVe Embeddings:\",score2)\n",
    "\n",
    "train_pred2_proba=model2.predict(train_pad)\n",
    "train_pred2=np.argmax(train_pred2_proba,axis=1)\n",
    "train_score2=f1_score(np.argmax(train_y,axis=1),train_pred2)\n",
    "print(\"F1 Score for Train data using GloVe Embeddings:\",train_score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GloVe Embeddings on the same model has increased the score significantly. Here again, the model is overfitting. Thus, we see that neural networks are extremely powerful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
